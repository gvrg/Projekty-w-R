---
title: "Analiza_SocialM"
author: "Gevorg Khangeldyan"
date: "29 listopada 2016"
output: html_document
---


# Samsung w mediach spo³ecznoœciowych

Wraz z rozwojem mediów spo³ecznoœciowych, coraz wiêcej istotnych danych mo¿emy znaleŸæ w materia³ach zamieszczonych przez samych u¿ytkowników. Tweety, posty, like’i s¹ ogromnym Ÿród³em wartoœciowych danych. Dlatego coraz istotniejsza jest umiejêtnoœæ œci¹gniêcia oraz analizowania tego typu informacji. W tej czêœci skupimy siê g³ównie na dwóch innych metodach analizowania teksów mianowicie Latent semantic analysis (LSA) oraz Latent Dirichlet allocation (LDA). 


## Zdobycie i przygotowanie tweetów

Dane zdobêdziemy z popularnego serwisu Twitter i œci¹gniemy wszystkie tweety, które zawieraj¹ w sobie s³owo klucz `samsung`.  Pos³u¿ymy siê w bibliotek¹ `twitteR` i œci¹gniemy 2000 tweet'ów od 1 czerwca 2016r.

```{r message=FALSE}
library(twitteR)
library(tm)
library(stringr)
library(stringi)
```

```{r, eval=FALSE}
samsung <- searchTwitter("samsung", n=1000, lang = "pl",  since = '2016-06-01')
```


```{r, echo=FALSE}
load("D:/Analityka/Dane/samsung.RData")
load("D:/Analityka/Dane/stopwords.pl")
```

Kolejnym etapem bêdzie wydobycie teksu z tweetów, wyczyszczenie oraz przygotowanie odpowiedniej formy
pod dalsz¹ analizê.

```{r}
samsung.txt <- sapply(samsung, function(x) x$getText())

clean_tweet <- function(x) {
  text <- unique(x)
  text <- str_replace_all(text, "[[:cntrl:]]", "")
  text <- str_replace_all(text, " https://t.co[[:graph:]]+","")
  text <- str_replace_all(text,"RT @[[:graph:]]*:","")
  text <- str_replace_all(text, "#[[:alnum:]_]*","")
  text <- str_replace_all(text,"@\\w+","")
  text <- stri_trans_general(text, "latin-ascii")
  return(text)
}

clean_corp <- function(corpus) {
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, removeNumbers)
  corpus <- tm_map(corpus, content_transformer(tolower))
  corpus <- tm_map(corpus, removeWords, words = c(stopwords_pl, "samsung"))
}

samsung_clean <- clean_tweet(samsung.txt)
length(samsung_clean)
samsung_corp <- VCorpus(VectorSource(samsung_clean))
samsung_corp_clean <- clean_corp(samsung_corp)
samsung_tdm <- TermDocumentMatrix(samsung_corp_clean)
samsung_tdm <- removeSparseTerms(samsung_tdm, 0.99)
```

Oto najczêœciej pojawiaj¹ce siê s³owa w zbiorze tekstów ze s³owem snooper. 

```{r}
findFreqTerms(samsung_tdm, lowfreq = 20)
```

## Latent Semantic Analysis (Analiza ukrytych grup semantycznych)


Analiza ukrytych grup semantycznych jest technik¹ która pozwala badaæ podobieñstwo tekstów. Dziêki niej
mo¿emy z du¿¹ skutecznoœci¹ oszacowaæ iloœæ g³ównych w¹tków zawartych w naszych tekstach.

```{r message=FALSE}
library(lsa)
library(ggplot2)
```

```{r}
samsung_mat <- as.matrix(samsung_tdm)

samsung_mat_lsa <- lw_bintf(samsung_mat) * gw_idf(samsung_mat)
lsa_space <- lsa(samsung_mat_lsa)
dist.samsung <- dist(t(as.textmatrix(lsa_space)))

fit <- cmdscale(dist.samsung, eig=TRUE, k = 2)
points <- data.frame(x=fit$points[,1], y = fit$points[,2])
```


Interpretacja wykresu jest interesuj¹ca. Mo¿na zauwa¿yæ jeden g³ówny w¹tek dotycz¹cy s³owa `samsung` (punkty w œrodku wykresu) oraz wiele innych w¹tków tworz¹ce dwie odnogi, liniowo oddalaj¹ce siê od g³ównego tematu. 
```{r}
ggplot(points, aes(x,y)) + 
  geom_jitter(col = "deepskyblue4") +
  theme_minimal()
```

##  Latent Dirichlet allocation (LDA)

Inn¹ metod¹ podobna do LSA jest Latent Dirichlet allocation (LDA) . Dziêki tej metodzie mo¿na uzyskaæ informacje dotycz¹ce s³ów kluczowych g³ównych w¹tków w zbiorze tekstów. W przeciwieñstwie do LSA technika LDA wykorzystuje Document Term Matrix a nie Term Document Matrix. 


```{r}
library(topicmodels)

dtm_samsung <- DocumentTermMatrix(samsung_corp_clean)
dtm_samsung <- removeSparseTerms(dtm_samsung, 0.99)
rowTotal <- apply(dtm_samsung, 1, sum)
dtm <- dtm_samsung[rowTotal > 0,]
```


W tym przypadku musimy rêcznie ustaliæ liczbê w¹tków, które bêdzie wyszukiwa³ algorytm. Wybierzmy ich 3. 

```{r}
lda_samsung <- LDA(dtm, k = 3)
term <- terms(lda_samsung, 8)
term <- apply(term, MARGIN = 2, FUN =  str_c, collapse = ", ")
```

```{r, echo=FALSE}
term
```

Algorytm poda³ nam 8 g³ównych s³ów wystêpuj¹cych w 3 wybranych przez nas w¹tkach. Na medium spo³ecznoœciowym `Tweeter` czêsto pojawiaj¹ siê tweety z wyrazami `galaxy`, `note`. Prawdopodobnie jest to spowodowane ostatnim modelem telefonu Galaxy Note 7, który wzbudzi³ spore zamieszanie w ostatnim czasie. W innym w¹tku pojawiaj¹ siê s³owa `led`. `hdmi`, `smart` i one dotycz¹ telewizorów produkowanych przez firmê *Samsung*. W ostatnim w¹tku czêsto wystêpuj¹ siê s³owa `galaxy` `tabpro` i dotycz¹c¹ one najnowszego tabletu wypuszczonego przez koreañsk¹ firmê. 



```{r echo=FALSE, message=FALSE, warning=F}
clean_corp_gal <- function(corpus) {
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, removeNumbers)
  corpus <- tm_map(corpus, content_transformer(tolower))
  corpus <- tm_map(corpus, removeWords, words = c(stopwords_pl, "samsung", "galaxy"))
}


fromCorpToDF <- function(doc) {
  doc <- TermDocumentMatrix(doc)
  doc <- as.matrix(doc)
  doc <- rowSums(doc)
  doc <- sort(doc, decreasing = TRUE)
  doc <- data.frame(name = names(doc),
                           num = doc)
}

samsung_clean_gal <- clean_corp_gal(samsung_corp)
samsungDF <- fromCorpToDF(samsung_clean_gal)

library(wordcloud)
library(RColorBrewer)

my_colors <- brewer.pal(10, "Dark2") 

wordcloud(samsungDF$name, samsungDF$num,
          max.words = 100, colors = my_colors)

```



## Podsumowanie

W drugiej czêœci zaprezentowano techniki analizy tekstów pochodz¹cych z mediów spo³ecznoœciowych. W po³¹czeniu z zaprezentowanymi tutaj LSA i LDA oraz wczeœniej opisanym modelowaniu predykcyjnym  daje potê¿ny zestaw narzêdzi do analizy danych pochodz¹cych z mediów spo³ecznoœciowych. Jednak wydaje siê, ¿e analiza tekstów, szczególnie krótkich komunikatów pochodz¹cych z mediów spo³ecznoœciowych jest bardziej wymagaj¹ca on analiz danych numerycznych i do jej wyników nale¿y podejœæ ostro¿niej. Jednak faktem jest to , ¿e analiza danych tekstowych jest istotnym i cennym Ÿród³em informacji w dzisiejszym œwiecie.
