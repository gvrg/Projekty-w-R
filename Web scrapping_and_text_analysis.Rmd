---
title: "Projekt_Samsung"
author: "Gevorg Khangeldyan"
date: "24 paŸdziernika 2016"
output: 
  pdf_document:
    number_section: true
    toc: true
---

\newpage

# Wstêp

Projekt_Samsung to plik przygotowany dla `Samsung Electronics`. Zawarte s¹ w nim przyk³ady technik stosowanych w `Data Science` w szczególnoœci w analizie danych tekstowych. W niniejszym dokumencie zastosowano m.in. techniki:

* zdobywania, obróbki i analizy tekstu pochodz¹cych ze stron html

* wizualizacji danych 

* tworzenie modeli predykcyjnych na podstawie danych tekstowych

* sci¹ganie danych tekstowych z portali spo³ecznoœciowych 

* analizy Latent Semantic Analysis oraz Latent Dirichlet allocation oraz  

\newpage


# Samsung Galaxy S5 na ceneo.pl

  Portal Ceneo.pl to strona zajmuj¹ca siê porównywaniem cen produktów. Na jej stronie mo¿na znaleŸæ równie¿ opinie zamieszczone przez u¿ytkowników. W sk³ad opinii wchodz¹: tekst napisany przez u¿ytkownika, liczba gwiazdek przypisana produktowi i czy produkt jest ogólnie polecany czy nie. Dla biznesu strony typu Ceneo.pl s¹  ogromnym Ÿród³em istotnych informacji, które mog¹ siê przydaæ w procesie podejmowania decyzji W  niniejszym przyk³adzie pos³u¿ono siê opiniami telefonu Samsung Galaxy S5, poniewa¿ produkt ten posiada relatywnie du¿o opinii (ponad 200), oraz znajduj¹ siê zarówno opinie rekomenduj¹ce telefon jak i odradzaj¹ce zakup.
  
## Uzyskiwanie danych ze strony internetowej

W celu uzyskania potrzebnych danych za³adowano odpowiednie biblioteki.

```{r message = FALSE}
library(RCurl)
library(XML)
library(stringr)
library(dplyr)
```

Po za³adowaniu bibliotek mo¿na przejœæ do napisania pêtli, która zajmie œci¹gniêciem stron internetowych na których znajduj¹ siê opinie. Do celu potrzebne bêd¹ strona bazowa Ceneo.pl, pierwsza strona [recenzji](http://www.ceneo.pl/28542739#tab=reviews), oraz œcie¿ka xpath umo¿liwiaj¹ca przejœcie do nastêpnej strony. Liczba stron recenzji wynosi w sumie 21.

```{r, eval=FALSE}
url <- getURL("http://www.ceneo.pl/28542739#tab=reviews")
baseurl <- "www.ceneo.pl"

path <- "//*[@class='page-arrow arrow-next']/a/@href"
lista_stron <- list()
lista_stron <- url

for (i in 2:21) {
  nastepna <- xpathSApply(htmlParse(lista_stron[[i-1]]), path)
  nastena <- unlist(nastepna)
  nastepna <- str_c(baseurl, nastepna)
  lista_stron[[i]] <- getURL(nastepna)
}
```

```{r, echo=FALSE}
load("D:/Analityka/Dane/lista_stron.RData")
```


```{r}
length(lista_stron)
```

Jak widaæ liczba stron w znajduj¹ca w liœcie 21, wiêc strony œci¹gnê³y siê prawid³owo. Teraz mo¿na przejœæ do œci¹gniêcia potrzebnych informacji. Dla potrzeb tego przypadku zostan¹ œci¹gniête opinie s³owne napisane przez u¿ytkownika oraz informacja czy produkt jest polecany b¹dŸ nie. Ta druga informacja pozwoli na sklasyfikowanie pozytywnych i negatywnych recenzji, co bêdzie potrzebne póŸniej.

Funkcja œci¹gaj¹ca opinie

```{r}
funOpinia <- function(x) {
  opi <- unlist(xpathApply(htmlParse(x), 
                               "//div[@class='content-wide-col']/p[position()=1 and not(contains(@class, 'product-question-title'))]",
                           xmlValue))
}

opinie <- unlist(lapply(lista_stron, funOpinia))
```

Funkcja œci¹gaj¹ca rekomendacje. 
```{r}
funRekomen <- function(x) {
  rekom <- unlist(xpathApply(htmlParse(x), 
                             "//div[@class='product-review-summary']/em", xmlValue))
}

rekomendacje <- unlist(lapply(lista_stron, funRekomen))
```


W tym miejscu warto dodaæ, ¿e œcie¿ka xpath dla opinii jest zdecydowanie d³u¿sza ni¿ dla rekomendacji. Zawiera w sobie dodatkowy cz³on filtruj¹cy /p[position()=1 oraz not(contains(@class, 'product-question-title'))]. Pierwszy ma zadanie filtrowanie tylko opinii, poniewa¿ Ceneo.pl umo¿liwia wpisywanie komentarzy pod opiniami. Bez pierwszego cz³onu R œci¹ga wszystkie komentarze co sprawia, ¿e d³ugoœæ  wektora opinii oraz rekomendacji jest ró¿na. Drugi cz³on uniemo¿liwia œci¹gniêcie pytañ zadawanych przez  internautów odnoœnie tego produktu. Pytania te znajduj¹ siê pod t¹ sama œcie¿k¹ xpath. Uwzglêdnienie tych pytañ te¿ sprawia ze d³ugoœæ wektorów opinii i rekomendacji jest ró¿na co uniemo¿liwia przypisane tych odpowiednich rekomendacji do opinii.


W sumie zosta³o œci¹gniêtych 206 opinii tekstowych i 206 rekomendacji z czego 21 odradza³o zakup produktu.


```{r}
length(opinie)

length(rekomendacje) == length(opinie)
```

```{r, include=FALSE}
opinie <- str_replace_all(opinie, "sie|siê", "")
dane_S5 <- data.frame(opinie = opinie, rekomendacje = rekomendacje)
```


```{r}
library(ggplot2)
ggplot(dane_S5, aes(x = rekomendacje)) + 
  geom_bar(fill = c("firebrick2", "deepskyblue4")) +
  theme_classic() +
  ggtitle("Samsung Galaxy S5") +
  ylab("Liczba")

```



## Tworzenie korpusu

Po zdobyciu potrzebnych informacji przechodzimy do jej analizy. Na  po³¹czymy opinie z rekomendacjami w data frame, by potem wyodrêbniæ‡ dobre i z³e opinie. 

```{r}
dane_S5 <- data.frame(opinie = opinie, rekomendacje = rekomendacje)
zle <- dane_S5[str_detect(dane_S5$rekomendacje, "Nie polecam"),] %>% select(opinie) 
dobre <- dane_S5[str_detect(dane_S5$rekomendacje, "Polecam"),] %>% select(opinie) 

```


Do analizy tekstu potrzebna bêdzie biblioteka tm, za pomoc¹ której stworzymy i wyczyœcimy corpus,  który bêdzie podstaw¹ do dalszej analizy tekstu.

```{r, message=FALSE}
library(tm)

dobre_source <- DataframeSource(dobre)
dobre_corp <- VCorpus(dobre_source)
zle_source <- DataframeSource(zle)
zle_corp <- VCorpus(zle_source)

```

Po stworzeniu korpusu dobrych i z³ych opinii przechodzimy do wyczyszczenia korpusu. Dla tego celu stworzono funkcje, która usprawni ten proces. 

```{r echo=FALSE}
source("D:/Analityka/Funkcje/stopwordsPL.R", encoding = 'windows-1250')
```

```{r}
clean_corp <- function(corpus) {
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, removeNumbers)
  corpus <- tm_map(corpus, content_transformer(tolower))
  corpus <- tm_map(corpus, removeWords, c(stopwords_pl, "telefon", "samsung", "galaxy", "polecam"))
}

clean_dobre <- clean_corp(dobre_corp)
clean_zle <- clean_corp(zle_corp)

```

## Wizualizacja

Dobrym i szybkim sposobem wizualizacji danych jest tzw. `wordcloud`. Pozwala w przystêpny sposób zobrazowaæ s³owa kluczowe i czêstotliwoœæ ich wystêpowania. Inny skutecznym (trochê mniej efektownym) sposobem jest bar plot, który przedstawia w inny sposób czêstotliwoœæ kluczowych s³ów.

```{r message=FALSE}
library(wordcloud)
library(RColorBrewer)

```

```{r}
fromCorpToDF <- function(doc) {
  doc <- TermDocumentMatrix(doc)
  doc <- as.matrix(doc)
  doc <- rowSums(doc)
  doc <- sort(doc, decreasing = TRUE)
  doc <- data.frame(name = names(doc),
                           num = doc)
}
zle_freq <- fromCorpToDF(clean_zle)
dobre_freq <- fromCorpToDF(clean_dobre)
```


```{r, message=FALSE, warning=FALSE}
my_colors <- brewer.pal(8, "Dark2") 

wordcloud(dobre_freq$name, dobre_freq$num,
          max.words = 70, colors = my_colors)

ggplot(dobre_freq[1:20,], aes(x = reorder(name, num), y = num, fill = name)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  guides(fill=FALSE) +
  theme_classic() +
  ylab("Liczba s³ów") +
  xlab("S³owa") +
  ggtitle("Recenzje pozytywne")


ggplot(zle_freq[1:20,], aes(x = reorder(name, num), y = num, fill = name)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  guides(fill=FALSE) +
  theme_classic() +
  ylab("Liczba s³ów") +
  xlab("S³owa")+
  ggtitle("Recenzje negatywne")
```

Jak widaæ z przedstawionych wykresów, pozytywne recenzje poza aprobuj¹cymi epitetami (super, dobry, œwietny, idealny), zawieraj¹ s³owa dotycz¹ce szybkoœci dzia³ania, aparatu, baterii, wyœwietlacza. Ciekawe jest to, ¿e w negatywnych recenzjach te¿ pojawia siê s³owa dotycz¹ce aparatu i baterii. Poza tym w negatywnych komentarzach bardzo czêsto wspomina siê o lte, aplikacjach oraz aktualizacjach. 

## Modelowanie

Wa¿nym procesem podczas analizy danych tekstowych jest tworzenie modeli predykcyjnych. Modele te, przy pomocy s³ów wystêpuj¹cych w tekœcie staraj¹ siê zaklasyfikowaæ dane teksty to okreœlonych przez analityka kategorii. Tutaj dziêki zebraniu informacji na temat tego czy konsumenci rekomenduj¹ produkt czy nie, stworzymy modele, które maj¹ za zadanie przewidzieæ za pomoc¹ samego tekstu czy recenzja poleca produkt czy jednak odradza jego zakup.

```{r, message=F}
library(RTextTools)
```

Przechodzimy przez standardow¹ procedurê tworzenia korpusu tekstu i wektora rekomendacji.  
```{r}
text <- dane_S5$opinie
oceny <- dane_S5$rekomendacje

text_corp <- VCorpus(VectorSource(text))

text_clean <- clean_corp(text_corp)
dtm <- DocumentTermMatrix(text_clean)
dtm <- removeSparseTerms(dtm, 0.99)

oceny_car <- as.character(oceny)
```

Nastêpnie tworzymy kontenera, który bêdzie zawiera³‚ informacje dotycz¹ce wielkoœci modelu trenuj¹cego oraz modelu testowanego. 150 obserwacji z 206 przeznaczymy na model trenuj¹cy a resztê na testowanie jakoœci modelu.

```{r}
N <- length(oceny_car)
container <- create_container(dtm,
                              labels = oceny_car,
                              trainSize = 1:150,
                              testSize = 151:N,                             
                              virgin = FALSE)

```

Teraz mo¿emy przejœæ do tworzenia modeli predykcyjnych. Jest wiele rodzajów modeli, my jednak skupimy siê na 3 najczêœciej spotkanych Support Vector Machine, Decision Tree Method oraz Maximum Entropy Method.

```{r}
svm_model <- train_model(container, "SVM")
tree_model <- train_model(container, "TREE" )
max_entr <- train_model(container, "MAXENT")

svm_out <- classify_model(container,  svm_model)
tree_out <- classify_model(container,  tree_model)
max_out <- classify_model(container,  max_entr)  

EvalDF <- data.frame(oceny_car[151:N],
                     svm = as.character(svm_out[,1]),
                     tree = as.character(tree_out[,1]),
                     maxent = as.character(max_out[,1]),
                     stringsAsFactors = FALSE)
```

SprawdŸmy jak  modele radz¹ sobie z predykacja tekstu.

* **Vector Suppor Machine**
```{r echo=FALSE}
prop.table(table(EvalDF[,1] == EvalDF[,2]))
```

* **Decision Tree Method** 
```{r echo=FALSE}
prop.table(table(EvalDF[,1] == EvalDF[,3]))
```

* **Maximum Entropy Method**
```{r echo=FALSE}
prop.table(table(EvalDF[,1] == EvalDF[,4]))
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(tidyr)
table <- rbind(VSM = table(EvalDF[,1] == EvalDF[,2]),
               TREE = table(EvalDF[,1] == EvalDF[,3]),
               MAX_ENT = table(EvalDF[,1] == EvalDF[,4])) 


table[1,1] <- 0
table <- as.data.frame(table)

name <- rownames(table)
table <-cbind(name, table)
table <-table %>% gather(result, value, -name)

ggplot(table, aes(name, value, fill = result)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme_classic() +
  ggtitle("Porównanie modeli") +
  ylab("Skutecznoœæ") +
  xlab("Model")
```


Jak widaæ wszystkie modele osi¹gaj¹ bardzo wysokie wskaŸniki.  Vector Suppor Machine model potrafi z 100% skutecznoœci¹ przewidzieæ czy tekst rekomenduje produkt czy nie. Wyniki osi¹gniêcie przez modele s¹ zachêcaj¹ce jednak zêby nie popaœæ w huraoptymizm nale¿y dodaæ, ¿e  wszystkie modele tutaj z ³atwoœci¹ powinny osi¹gn¹æ ponad 90% skutecznoœæ, gdy¿  taki by³by wynik, gdybyœmy na œlepo przypisali wszystkie teksty do ocen rekomenduj¹cych.


$$Produkt Rekomandowany \div Wszystkie Produkty = \frac{185}{206} = 90\%$$

Dlatego te¿ wynik  modelu MAX_ENT,  który osi¹gn¹³ w tym przypadku 92%  nie jest ju¿ wcale taki zachwycaj¹cy 

##Podsumowanie
 
 W powy¿szej czêœci siê skupiliœmy siê na wa¿nej czêœci pracy w data science, czyli operacji na nieustrukturyzowanych danych tekstowych pochodz¹cych z Internetu. W biznesie  coraz to wiêksza wartoœæ maja opinie klientów zamieszczone w Internecie poniewa¿ dostarczaj¹ natychmiastowego feedback’u odnoœnie produktów. 
Eksploruj¹c tekst wykorzystano popularne techniki wizualizacyjne, które w prosty i przystêpny sposób potrafi¹ zakomunikowaæ wa¿ne informacje dostêpne w tekœcie. Z kolei tworzenie tekstowych modeli predykcyjnych umo¿liwia natychmiastow¹ klasyfikacje ogromnej treœci danych tekstowych. Szczególnie s¹ one przydatne do analizy treœci powsta³ych w mediach spo³ecznoœciowych, które bez technik wy¿ej opisanych, by³yby niemo¿liwe do ogarniêcia.
